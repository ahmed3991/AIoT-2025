{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v45v2zeZdZDd"
      },
      "outputs": [],
      "source": [
        "import os, pickle, warnings, sys\n",
        "from time import perf_counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "USE_DEMO_DATA = True   # â† Ù„Ùˆ Ù„Ø¯ÙŠÙƒ X_train... ØºÙŠÙ‘Ø±Ù‡Ø§ Ø¥Ù„Ù‰ False ÙˆØ§Ø³ØªØ®Ø¯Ù… Ù‚Ø³Ù… \"YOUR DATA\" Ø¨Ø§Ù„Ø£Ø³ÙÙ„\n",
        "SAVE_DIR = \"./outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "VlrayDxyd16T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_demo_data(test_size=0.2, random_state=SEED):\n",
        "    from sklearn.datasets import load_breast_cancer\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "1M-22Pr2d4ch"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_your_data():\n",
        "    # Ù…Ø«Ø§Ù„ (Ø¹Ø¯Ù‘Ù„ Ø­Ø³Ø¨ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ):\n",
        "    # return X_train, X_test, y_train, y_test\n",
        "    return None\n",
        "\n",
        "if USE_DEMO_DATA:\n",
        "    X_train, X_test, y_train, y_test = load_demo_data()\n",
        "else:\n",
        "    maybe = load_your_data()\n",
        "    if maybe is None:\n",
        "        raise ValueError(\"Ø±Ø¬Ø§Ø¡Ù‹ Ø²ÙˆÙ‘Ø¯ X_train, X_test, y_train, y_test ÙÙŠ load_your_data().\")\n"
      ],
      "metadata": {
        "id": "sZvT6v8Rd6le"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lr_pipeline():\n",
        "    return Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", LogisticRegression(max_iter=1000, solver=\"lbfgs\", random_state=SEED))\n",
        "    ])\n",
        "\n",
        "def build_xgb_pipeline():\n",
        "    try:\n",
        "        from xgboost import XGBClassifier\n",
        "    except Exception as e:\n",
        "        print(\"âš ï¸ XGBoost ØºÙŠØ± Ù…Ø«Ø¨Øª. Ø«Ø¨Ù‘Øª Ø§Ù„Ø­Ø²Ù…Ø© Ø«Ù… Ø£Ø¹Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„: pip install xgboost\")\n",
        "        return None\n",
        "    return Pipeline([\n",
        "        (\"scaler\", StandardScaler()),   # Ø«Ø§Ø¨Øª Ù„Ù„ØªÙˆØ­ÙŠØ¯ Ù…Ø¹ Ø§Ù„Ù€ MLOps\n",
        "        (\"clf\", XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=4,\n",
        "            learning_rate=0.1,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            reg_lambda=1.0,\n",
        "            tree_method=\"hist\",  # Ø£Ø³Ø±Ø¹/Ø£Ø®Ù Ø¹Ø§Ø¯Ø©\n",
        "            n_jobs=1,\n",
        "            random_state=SEED,\n",
        "            eval_metric=\"logloss\",\n",
        "        ))\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "67420LsRd9jQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval(pipe, name, X_train, y_train, X_test, y_test):\n",
        "    t0 = perf_counter()\n",
        "    pipe.fit(X_train, y_train)\n",
        "    train_time_s = perf_counter() - t0\n",
        "\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "    return {\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"F1\": f1,\n",
        "        \"Train_Time_s\": train_time_s\n",
        "    }"
      ],
      "metadata": {
        "id": "5iuNDdHbeAwF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_model_size(pipe, out_path):\n",
        "    b = pickle.dumps(pipe, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    with open(out_path, \"wb\") as f:\n",
        "        f.write(b)\n",
        "    size_kb = len(b) / 1024.0\n",
        "    return size_kb\n"
      ],
      "metadata": {
        "id": "pNVsNYbReFAf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_inference_time(pipe, X_test):\n",
        "    t0 = perf_counter()\n",
        "    _ = pipe.predict(X_test)\n",
        "    total_s = perf_counter() - t0\n",
        "    single_ms = (total_s / len(X_test)) * 1000.0\n",
        "    return total_s, single_ms\n"
      ],
      "metadata": {
        "id": "htN0rujzeG9y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_metrics = []\n",
        "results_sizes = []\n",
        "results_timing = []\n"
      ],
      "metadata": {
        "id": "DmBo7_sQeIyG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_pipe = build_lr_pipeline()\n",
        "lr_metrics = train_and_eval(lr_pipe, \"LR-Pipeline\", X_train, y_train, X_test, y_test)\n",
        "lr_size_kb = measure_model_size(lr_pipe, os.path.join(SAVE_DIR, \"lr_pipeline.pkl\"))\n",
        "lr_inf_total_s, lr_inf_single_ms = measure_inference_time(lr_pipe, X_test)\n",
        "\n",
        "results_metrics.append(lr_metrics)\n",
        "results_sizes.append({\"Model\": \"LR-Pipeline\", \"Size_KB\": lr_size_kb})\n",
        "results_timing.append({\n",
        "    \"Model\": \"LR-Pipeline\",\n",
        "    \"Total_Test_Inference_Time_s\": lr_inf_total_s,\n",
        "    \"Single_Inference_Time_ms\": lr_inf_single_ms\n",
        "})"
      ],
      "metadata": {
        "id": "nUmbLXH2eKvV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_pipe = build_xgb_pipeline()\n",
        "if xgb_pipe is not None:\n",
        "    xgb_metrics = train_and_eval(xgb_pipe, \"XGB-Pipeline\", X_train, y_train, X_test, y_test)\n",
        "    xgb_size_kb = measure_model_size(xgb_pipe, os.path.join(SAVE_DIR, \"xgb_pipeline.pkl\"))\n",
        "    xgb_inf_total_s, xgb_inf_single_ms = measure_inference_time(xgb_pipe, X_test)\n",
        "\n",
        "    results_metrics.append(xgb_metrics)\n",
        "    results_sizes.append({\"Model\": \"XGB-Pipeline\", \"Size_KB\": xgb_size_kb})\n",
        "    results_timing.append({\n",
        "        \"Model\": \"XGB-Pipeline\",\n",
        "        \"Total_Test_Inference_Time_s\": xgb_inf_total_s,\n",
        "        \"Single_Inference_Time_ms\": xgb_inf_single_ms\n",
        "    })\n"
      ],
      "metadata": {
        "id": "komGY7XheOTR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = pd.DataFrame(results_metrics).set_index(\"Model\")\n",
        "sizes_df   = pd.DataFrame(results_sizes).set_index(\"Model\")\n",
        "timing_df  = pd.DataFrame(results_timing).set_index(\"Model\")\n",
        "\n",
        "metrics_path = os.path.join(SAVE_DIR, \"metrics.csv\")\n",
        "sizes_path   = os.path.join(SAVE_DIR, \"model_sizes.csv\")\n",
        "timing_path  = os.path.join(SAVE_DIR, \"inference_times.csv\")\n",
        "\n",
        "metrics_df.to_csv(metrics_path)\n",
        "sizes_df.to_csv(sizes_path)\n",
        "timing_df.to_csv(timing_path)\n",
        "\n",
        "print(\"\\n===== Task 1: Scores =====\")\n",
        "print(metrics_df.round(4))\n",
        "print(\"\\n===== Task 2.1: Model Sizes (KB) =====\")\n",
        "print(sizes_df.round(2))\n",
        "print(\"\\n===== Task 2.2: Inference Times =====\")\n",
        "print(timing_df.round(6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCafju_jeQ1X",
        "outputId": "235db039-03f5-401c-c6d9-64c0b408d4bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Task 1: Scores =====\n",
            "              Accuracy      F1  Train_Time_s\n",
            "Model                                       \n",
            "LR-Pipeline     0.9825  0.9825        0.0730\n",
            "XGB-Pipeline    0.9561  0.9558        0.1675\n",
            "\n",
            "===== Task 2.1: Model Sizes (KB) =====\n",
            "              Size_KB\n",
            "Model                \n",
            "LR-Pipeline      2.61\n",
            "XGB-Pipeline   104.52\n",
            "\n",
            "===== Task 2.2: Inference Times =====\n",
            "              Total_Test_Inference_Time_s  Single_Inference_Time_ms\n",
            "Model                                                              \n",
            "LR-Pipeline                      0.012247                  0.107430\n",
            "XGB-Pipeline                     0.009566                  0.083915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.3: ESP32 Analysis (auto paragraph)"
      ],
      "metadata": {
        "id": "gmYQlVL_eaem"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62a33869"
      },
      "source": [
        "def esp32_analysis_text(sizes_df, timing_df):\n",
        "    # Ù…ÙˆØ§ØµÙØ§Øª ØªÙ‚Ø±ÙŠØ¨ÙŠØ©: RAM ~ 520 KBØŒ Flash Ø¨Ø¹Ø¯Ø© Ù…ÙŠØºØ§Ø¨Ø§ÙŠØª (Ø­Ø³Ø¨ Ø§Ù„Ù„ÙˆØ­Ø©)\n",
        "    SRAM_KB = 520.0\n",
        "    ONE_SEC_BUDGET_MS = 1000.0  # Ù…Ø«Ø§Ù„: Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙƒÙ„ Ø«Ø§Ù†ÙŠØ©\n",
        "\n",
        "    def row_or_none(df, name):\n",
        "        return df.loc[name] if name in df.index else None\n",
        "\n",
        "    lr_s = row_or_none(sizes_df, \"LR-Pipeline\")\n",
        "    xg_s = row_or_none(sizes_df, \"XGB-Pipeline\")\n",
        "    lr_t = row_or_none(timing_df, \"LR-Pipeline\")\n",
        "    xg_t = row_or_none(timing_df, \"XGB-Pipeline\")\n",
        "\n",
        "    lines = []\n",
        "    lines.append(\"ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø§Ù‡Ø²ÙŠØ© Ù„Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ ESP32:\\n\")\n",
        "\n",
        "    # Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n",
        "    lines.append(\"1) Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© Ø§Ù„Ø°Ø§ÙƒØ±ÙŠØ©:\")\n",
        "    if lr_s is not None:\n",
        "        lines.append(f\"   â€¢ LR: Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ â‰ˆ {lr_s['Size_KB']:.1f} KB (ÙŠÙØ®Ø²Ù‘ÙÙ† Ø¹Ø§Ø¯Ø©Ù‹ ÙÙŠ Ø§Ù„Ù€Flash ÙˆÙŠÙØ­Ù…Ù‘ÙÙ„ Ø¬Ø²Ø¦ÙŠÙ‹Ø§/ÙƒØ§Ù…Ù„Ù‹Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù€SRAM ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„).\")\n",
        "    if xg_s is not None:\n",
        "        lines.append(f\"   â€¢ XGB: Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ â‰ˆ {xg_s['Size_KB']:.1f} KB.\")\n",
        "    lines.append(f\"   - Ù‚ÙŠØ§Ø³ Ù…Ø±Ø¬Ø¹ÙŠ: ESP32 ÙŠÙ…Ù„Ùƒ Ù†Ø­Ùˆ {SRAM_KB:.0f} KB SRAM Ø¥Ø¬Ù…Ø§Ù„ÙŠ (ÙˆØ§Ù„Ø­ÙŠÙ‘Ø² Ø§Ù„Ù…ØªØ§Ø­ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ Ø£Ù‚Ù„ Ù…Ù† Ø°Ù„Ùƒ).\")\n",
        "    if (lr_s is not None) and (xg_s is not None):\n",
        "        more_constrained = \"XGB-Pipeline\" if xg_s['Size_KB'] > lr_s['Size_KB'] else \"LR-Pipeline\"\n",
        "        lines.append(f\"   â‡’ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙ‚ÙŠÙŠØ¯Ù‹Ø§ Ù…Ù† Ù†Ø§Ø­ÙŠØ© Ø§Ù„Ø­Ø¬Ù… Ù‡Ùˆ: {more_constrained}.\")\n",
        "    lines.append(\"\")\n",
        "\n",
        "    # Ø§Ù„Ø²Ù…Ù†\n",
        "    lines.append(\"2) Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© (Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¢Ù†Ù ÙƒÙ„ 1 Ø«Ø§Ù†ÙŠØ© ÙƒÙ…Ø«Ø§Ù„):\")\n",
        "    if lr_t is not None:\n",
        "        lines.append(f\"   â€¢ LR: Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ù…ÙØ±Ø¯ â‰ˆ {lr_t['Single_Inference_Time_ms']:.3f} ms.\")\n",
        "    if xg_t is not None:\n",
        "        lines.append(f\"   â€¢ XGB: Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ù…ÙØ±Ø¯ â‰ˆ {xg_t['Single_Inference_Time_ms']:.3f} ms.\")\n",
        "    lines.append(f\"   - Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© ~{ONE_SEC_BUDGET_MS:.0f} ms/Ø«ØŒ ÙƒÙ„Ø§Ù‡Ù…Ø§ Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ù‚Ø¨ÙˆÙ„ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø²Ù…Ù† Ø¨Ø§Ù„Ù…Ù„Ù‘ÙŠ Ø«ÙˆØ§Ù†Ù Ø£Ø­Ø§Ø¯ÙŠØ© Ø£Ùˆ Ø¹Ø´Ø±Ø§Øª Ù‚Ù„ÙŠÙ„Ø©.\")\n",
        "    lines.append(\"\")\n",
        "\n",
        "    # Ø§Ù„Ø®Ù„Ø§ØµØ© + ØªØ­Ø³ÙŠÙ†Ø§Øª\n",
        "    choice = None\n",
        "    if (lr_s is not None) and (xg_s is not None) and (lr_t is not None) and (xg_t is not None):\n",
        "        # Ù‚Ø±Ø§Ø± Ø¨Ø³ÙŠØ·: Ø§Ø®ØªØ± Ø§Ù„Ø£ØµØºØ± ÙˆØ§Ù„Ø£Ø³Ø±Ø¹\n",
        "        score_lr  = lr_s['Size_KB'] * 0.5 + lr_t['Single_Inference_Time_ms'] * 0.5\n",
        "        score_xgb = xg_s['Size_KB'] * 0.5 + xg_t['Single_Inference_Time_ms'] * 0.5\n",
        "        choice = \"LR-Pipeline\" if score_lr <= score_xgb else \"XGB-Pipeline\"\n",
        "    elif lr_s is not None and lr_t is not None:\n",
        "        choice = \"LR-Pipeline\"\n",
        "\n",
        "    lines.append(\"3) Ø§Ù„Ø®Ù„Ø§ØµØ©:\")\n",
        "    if choice is not None:\n",
        "        lines.append(f\"   â€¢ Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£Ù†Ø³Ø¨ Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ Ø§Ù„ÙƒÙØ§Ø¡Ø© ÙˆÙ‚ÙŠÙˆØ¯ ESP32: **{choice}**.\")\n",
        "    else:\n",
        "        lines.append(\"   â€¢ ØªØ¹Ø°Ù‘Ø± Ø§Ù„Ø­Ø³Ù… Ù„ØºÙŠØ§Ø¨ Ù‚ÙŠØ§Ø³Ø§Øª Ø£Ø­Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ†.\")\n",
        "\n",
        "    lines.append(\"   â€¢ Ù„Ùˆ Ø§Ø­ØªØ¬Øª Ù„Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ù‚Ù„ ÙƒÙØ§Ø¡Ø©: Ø§Ø³ØªØ®Ø¯Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† Ù…Ø«Ù„: ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§ØªØŒ Ø§Ù„ØªÙƒÙ…ÙŠÙ… 8-bit Ø£Ùˆ fixed-pointØŒ ØªÙ‚Ù„ÙŠÙ„ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø¬Ø§Ø±/Ø§Ù„Ø¹Ù…Ù‚ (Ù„Ù€XGB)ØŒ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ C/MCU Ø¹Ø¨Ø± m2cgen Ø£Ùˆ TreeliteØŒ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø£Ø­Ø§Ø¯ÙŠ Ø§Ù„Ø®ÙŠØ·ØŒ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø°Ø§ÙƒØ±Ø© ØµØ§Ø±Ù…Ø©.\")\n",
        "    return \"\\n\".join(lines)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== Task 2.3: ESP32 Analysis =====\")\n",
        "print(esp32_analysis_text(sizes_df, timing_df))\n",
        "\n",
        "print(f\"\\nğŸ“ Saved to: {os.path.abspath(SAVE_DIR)}\")\n",
        "print(\" - metrics.csv (Ø§Ù„Ø¯Ù‚Ø© Ùˆ F1 ÙˆØ²Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨)\")\n",
        "print(\" - model_sizes.csv (Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø§Ù„Ù€KB)\")\n",
        "print(\" - inference_times.csv (Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„ÙƒÙ„Ù‘ÙŠ ÙˆØ§Ù„Ù…ÙØ±Ø¯)\")\n",
        "print(\" - lr_pipeline.pkl / xgb_pipeline.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veQJ5tnxkCSS",
        "outputId": "06467f04-7047-4a5d-f491-b3d85c2c8f85"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Task 2.3: ESP32 Analysis =====\n",
            "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø§Ù‡Ø²ÙŠØ© Ù„Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ ESP32:\n",
            "\n",
            "1) Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© Ø§Ù„Ø°Ø§ÙƒØ±ÙŠØ©:\n",
            "   â€¢ LR: Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ â‰ˆ 2.6 KB (ÙŠÙØ®Ø²Ù‘ÙÙ† Ø¹Ø§Ø¯Ø©Ù‹ ÙÙŠ Ø§Ù„Ù€Flash ÙˆÙŠÙØ­Ù…Ù‘ÙÙ„ Ø¬Ø²Ø¦ÙŠÙ‹Ø§/ÙƒØ§Ù…Ù„Ù‹Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù€SRAM ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„).\n",
            "   â€¢ XGB: Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ â‰ˆ 104.5 KB.\n",
            "   - Ù‚ÙŠØ§Ø³ Ù…Ø±Ø¬Ø¹ÙŠ: ESP32 ÙŠÙ…Ù„Ùƒ Ù†Ø­Ùˆ 520 KB SRAM Ø¥Ø¬Ù…Ø§Ù„ÙŠ (ÙˆØ§Ù„Ø­ÙŠÙ‘Ø² Ø§Ù„Ù…ØªØ§Ø­ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ Ø£Ù‚Ù„ Ù…Ù† Ø°Ù„Ùƒ).\n",
            "   â‡’ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙ‚ÙŠÙŠØ¯Ù‹Ø§ Ù…Ù† Ù†Ø§Ø­ÙŠØ© Ø§Ù„Ø­Ø¬Ù… Ù‡Ùˆ: XGB-Pipeline.\n",
            "\n",
            "2) Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© (Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¢Ù†Ù ÙƒÙ„ 1 Ø«Ø§Ù†ÙŠØ© ÙƒÙ…Ø«Ø§Ù„):\n",
            "   â€¢ LR: Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ù…ÙØ±Ø¯ â‰ˆ 0.107 ms.\n",
            "   â€¢ XGB: Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ù…ÙØ±Ø¯ â‰ˆ 0.084 ms.\n",
            "   - Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© ~1000 ms/Ø«ØŒ ÙƒÙ„Ø§Ù‡Ù…Ø§ Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ù‚Ø¨ÙˆÙ„ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø²Ù…Ù† Ø¨Ø§Ù„Ù…Ù„Ù‘ÙŠ Ø«ÙˆØ§Ù†Ù Ø£Ø­Ø§Ø¯ÙŠØ© Ø£Ùˆ Ø¹Ø´Ø±Ø§Øª Ù‚Ù„ÙŠÙ„Ø©.\n",
            "\n",
            "3) Ø§Ù„Ø®Ù„Ø§ØµØ©:\n",
            "   â€¢ Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£Ù†Ø³Ø¨ Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ Ø§Ù„ÙƒÙØ§Ø¡Ø© ÙˆÙ‚ÙŠÙˆØ¯ ESP32: **LR-Pipeline**.\n",
            "   â€¢ Ù„Ùˆ Ø§Ø­ØªØ¬Øª Ù„Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ù‚Ù„ ÙƒÙØ§Ø¡Ø©: Ø§Ø³ØªØ®Ø¯Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† Ù…Ø«Ù„: ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§ØªØŒ Ø§Ù„ØªÙƒÙ…ÙŠÙ… 8-bit Ø£Ùˆ fixed-pointØŒ ØªÙ‚Ù„ÙŠÙ„ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø¬Ø§Ø±/Ø§Ù„Ø¹Ù…Ù‚ (Ù„Ù€XGB)ØŒ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ C/MCU Ø¹Ø¨Ø± m2cgen Ø£Ùˆ TreeliteØŒ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø£Ø­Ø§Ø¯ÙŠ Ø§Ù„Ø®ÙŠØ·ØŒ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø°Ø§ÙƒØ±Ø© ØµØ§Ø±Ù…Ø©.\n",
            "\n",
            "ğŸ“ Saved to: /content/outputs\n",
            " - metrics.csv (Ø§Ù„Ø¯Ù‚Ø© Ùˆ F1 ÙˆØ²Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨)\n",
            " - model_sizes.csv (Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø§Ù„Ù€KB)\n",
            " - inference_times.csv (Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„ÙƒÙ„Ù‘ÙŠ ÙˆØ§Ù„Ù…ÙØ±Ø¯)\n",
            " - lr_pipeline.pkl / xgb_pipeline.pkl\n"
          ]
        }
      ]
    }
  ]
}