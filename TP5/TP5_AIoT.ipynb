{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Task 1.1: Environment Setup and Data Loading\n"
      ],
      "metadata": {
        "id": "NzZdRnoJfX_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "MaVNe59jfaVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fashion-MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxxYl-kzfyjU",
        "outputId": "5ae003bf-e908-49f5-c3df-7cb9948de4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "H4kcjjyNgjkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for MLP (flattened)\n",
        "x_train_mlp = x_train.reshape(x_train.shape[0], 28, 28)\n",
        "x_test_mlp = x_test.reshape(x_test.shape[0], 28, 28)"
      ],
      "metadata": {
        "id": "ynMHPgYXglI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for CNN (add channel dimension)\n",
        "x_train_cnn = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test_cnn = x_test.reshape(x_test.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "S6ZfkAbZgom8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset shapes:\")\n",
        "print(f\"Original train images: {x_train.shape}\")\n",
        "print(f\"MLP train images: {x_train_mlp.shape}\")\n",
        "print(f\"CNN train images: {x_train_cnn.shape}\")\n",
        "print(f\"Train labels: {y_train.shape}\")\n",
        "print(f\"Test images: {x_test.shape}\")\n",
        "print(f\"Test labels: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtY60WKrgtu4",
        "outputId": "8c6234bf-0b47-4e5a-fc2e-646a83da5dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shapes:\n",
            "Original train images: (60000, 28, 28)\n",
            "MLP train images: (60000, 28, 28)\n",
            "CNN train images: (60000, 28, 28, 1)\n",
            "Train labels: (60000,)\n",
            "Test images: (10000, 28, 28)\n",
            "Test labels: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.1: Implement and Compile the MLP Model"
      ],
      "metadata": {
        "id": "HwAboPwigyj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSyb9P_Lg3Er",
        "outputId": "b8ae2c28-b3ba-4dd4-c3d4-464366911a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "c8ZIKz1xhGYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MLP Model Summary:\")\n",
        "print(\"=\"*50)\n",
        "mlp_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "O5cfmYT5hM1q",
        "outputId": "6aa6c35f-07c4-40c0-a4e7-d1a2abe83266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MLP Model Summary:\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.2: Implement and Compile the CNN Model"
      ],
      "metadata": {
        "id": "7pUAInZthQPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhUiy01lhTFi",
        "outputId": "6188efd5-cbbd-4e67-c7db-04a5dfc10b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "7itGJZmlhX-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CNN Model Summary:\")\n",
        "print(\"=\"*50)\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "Fgcr-UhEhbzL",
        "outputId": "23e6bd08-4cf8-4436-fd61-db66eca80646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "CNN Model Summary:\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m51,264\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,714\u001b[0m (221.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,714</span> (221.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,714\u001b[0m (221.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,714</span> (221.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3.1: Train the MLP"
      ],
      "metadata": {
        "id": "j8oGw2FbhfMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training MLP Model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "history_mlp = mlp_model.fit(\n",
        "    x_train_mlp, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    validation_data=(x_test_mlp, y_test),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ARbZ4LDhh_u",
        "outputId": "5bfcc659-f066-4b63-bea4-e10f96c54f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training MLP Model...\n",
            "==================================================\n",
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7781 - loss: 0.6350 - val_accuracy: 0.8448 - val_loss: 0.4270\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8645 - loss: 0.3698 - val_accuracy: 0.8631 - val_loss: 0.3815\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8801 - loss: 0.3272 - val_accuracy: 0.8644 - val_loss: 0.3735\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.3014 - val_accuracy: 0.8709 - val_loss: 0.3611\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8964 - loss: 0.2827 - val_accuracy: 0.8705 - val_loss: 0.3547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3.2: Train the CNN"
      ],
      "metadata": {
        "id": "MQftT4dphukt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training CNN Model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "history_cnn = cnn_model.fit(\n",
        "    x_train_cnn, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    validation_data=(x_test_cnn, y_test),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmcb7oMihvRZ",
        "outputId": "fc9f5acd-9f36-41b2-a4d2-523a703f6091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training CNN Model...\n",
            "==================================================\n",
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.7204 - loss: 0.7823 - val_accuracy: 0.8551 - val_loss: 0.4107\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.8640 - loss: 0.3817 - val_accuracy: 0.8769 - val_loss: 0.3558\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.8835 - loss: 0.3219 - val_accuracy: 0.8807 - val_loss: 0.3304\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.8933 - loss: 0.2948 - val_accuracy: 0.8843 - val_loss: 0.3128\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.9032 - loss: 0.2681 - val_accuracy: 0.8904 - val_loss: 0.3008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3.3: Evaluate and Report"
      ],
      "metadata": {
        "id": "6aejG67JiDIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Model Evaluation Results:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Evaluate MLP\n",
        "test_loss_mlp, test_accuracy_mlp = mlp_model.evaluate(x_test_mlp, y_test, verbose=0)\n",
        "print(f\"MLP Model - Test Loss: {test_loss_mlp:.4f}, Test Accuracy: {test_accuracy_mlp:.4f}\")\n",
        "\n",
        "# Evaluate CNN\n",
        "test_loss_cnn, test_accuracy_cnn = cnn_model.evaluate(x_test_cnn, y_test, verbose=0)\n",
        "print(f\"CNN Model - Test Loss: {test_loss_cnn:.4f}, Test Accuracy: {test_accuracy_cnn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66BtK_67iEI3",
        "outputId": "4d9c9e7f-e063-4d1f-8634-84e37e85cb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Model Evaluation Results:\n",
            "==================================================\n",
            "MLP Model - Test Loss: 0.3547, Test Accuracy: 0.8705\n",
            "CNN Model - Test Loss: 0.3008, Test Accuracy: 0.8904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.1: Count Trainable Parameters"
      ],
      "metadata": {
        "id": "I6kLf8efiOvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
        "    non_trainable_params = np.sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
        "    return trainable_params, non_trainable_params\n",
        "\n",
        "mlp_trainable, mlp_non_trainable = count_parameters(mlp_model)\n",
        "cnn_trainable, cnn_non_trainable = count_parameters(cnn_model)\n",
        "\n",
        "print(f\"\\nMLP Trainable Parameters: {mlp_trainable:,}\")\n",
        "print(f\"CNN Trainable Parameters: {cnn_trainable:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwWPGu9JiPuF",
        "outputId": "31d9d4a5-bf16-4f0e-e075-8b791386bf8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP Trainable Parameters: 235,146\n",
            "CNN Trainable Parameters: 56,714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.2: Estimate Memory Footprint"
      ],
      "metadata": {
        "id": "k7SHMlwfjW5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "mlp_model.save('mlp_model.h5')\n",
        "cnn_model.save('cnn_model.h5')\n",
        "\n",
        "# Get file sizes\n",
        "mlp_size = os.path.getsize('mlp_model.h5') / (1024 * 1024)  # Convert to MB\n",
        "cnn_size = os.path.getsize('cnn_model.h5') / (1024 * 1024)  # Convert to MB\n",
        "\n",
        "print(f\"\\nMLP Model Size: {mlp_size:.2f} MB\")\n",
        "print(f\"CNN Model Size: {cnn_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hptoJLHWjYlZ",
        "outputId": "b206aa3c-b960-4ffd-abae-14cc75e33232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP Model Size: 2.72 MB\n",
            "CNN Model Size: 0.69 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.3: Estimate Computational Resources"
      ],
      "metadata": {
        "id": "XBRJHiIujgOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_flops_and_memory(model, input_shape, batch_size=64):\n",
        "    \"\"\"\n",
        "    Estimate FLOPs and memory usage for training and inference\n",
        "    Note: This is a simplified estimation\n",
        "    \"\"\"\n",
        "\n",
        "    # Count total parameters\n",
        "    total_params = sum([np.prod(layer.get_weights()[0].shape) if layer.get_weights() else 0\n",
        "                       for layer in model.layers])\n",
        "\n",
        "\n",
        "    # This varies by layer type but we use a rough estimate\n",
        "    inference_flops = total_params * 2\n",
        "    training_flops = inference_flops * 3\n",
        "\n",
        "    # Memory estimation (parameters + gradients + optimizer state)\n",
        "    param_memory = total_params * 4 / (1024 * 1024)\n",
        "    training_memory = param_memory * 3\n",
        "\n",
        "    return inference_flops, training_flops, training_memory\n",
        "\n",
        "# Estimate for MLP\n",
        "mlp_inf_flops, mlp_train_flops, mlp_train_mem = estimate_flops_and_memory(mlp_model, (28, 28))\n",
        "\n",
        "# Estimate for CNN\n",
        "cnn_inf_flops, cnn_train_flops, cnn_train_mem = estimate_flops_and_memory(cnn_model, (28, 28, 1))\n",
        "\n",
        "print(f\"\\nComputational Resources Estimation:\")\n",
        "print(f\"MLP - Inference FLOPs: {mlp_inf_flops:,.0f}, Training FLOPs: {mlp_train_flops:,.0f}, Training Memory: {mlp_train_mem:.2f} MB\")\n",
        "print(f\"CNN - Inference FLOPs: {cnn_inf_flops:,.0f}, Training FLOPs: {cnn_train_flops:,.0f}, Training Memory: {cnn_train_mem:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTYA11ApjhWc",
        "outputId": "96bd4418-4bed-4a54-fd63-df0017221351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computational Resources Estimation:\n",
            "MLP - Inference FLOPs: 469,504, Training FLOPs: 1,408,512, Training Memory: 2.69 MB\n",
            "CNN - Inference FLOPs: 113,184, Training FLOPs: 339,552, Training Memory: 0.65 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5.1: Final Report and Conclusion"
      ],
      "metadata": {
        "id": "El66CuJPkSL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL COMPARISON REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create comparison table\n",
        "comparison_data = [\n",
        "    [\"Model\", \"Test Accuracy\", \"Trainable Parameters\", \"Model Size (MB)\", \"FLOPs (Training)\", \"FLOPs (Inference)\", \"Training Memory (MB)\"],\n",
        "    [\"MLP\", f\"{test_accuracy_mlp:.4f}\", f\"{mlp_trainable:,}\", f\"{mlp_size:.2f}\", f\"{mlp_train_flops:,.0f}\", f\"{mlp_inf_flops:,.0f}\", f\"{mlp_train_mem:.2f}\"],\n",
        "    [\"CNN\", f\"{test_accuracy_cnn:.4f}\", f\"{cnn_trainable:,}\", f\"{cnn_size:.2f}\", f\"{cnn_train_flops:,.0f}\", f\"{cnn_inf_flops:,.0f}\", f\"{cnn_train_mem:.2f}\"]\n",
        "]\n",
        "\n",
        "# Print formatted table\n",
        "for row in comparison_data:\n",
        "    print(f\"{row[0]:<15} {row[1]:<15} {row[2]:<20} {row[3]:<15} {row[4]:<15} {row[5]:<15} {row[6]:<15}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANALYSIS AND CONCLUSIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Answer the questions\n",
        "print(\"\\n1. Which model achieved a higher accuracy?\")\n",
        "if test_accuracy_cnn > test_accuracy_mlp:\n",
        "    print(f\"   ✓ CNN model achieved higher accuracy ({test_accuracy_cnn:.4f} vs {test_accuracy_mlp:.4f})\")\n",
        "else:\n",
        "    print(f\"   ✓ MLP model achieved higher accuracy ({test_accuracy_mlp:.4f} vs {test_accuracy_cnn:.4f})\")\n",
        "\n",
        "print(\"\\n2. Which model had a smaller number of parameters (lower memory footprint)?\")\n",
        "if cnn_trainable < mlp_trainable:\n",
        "    print(f\"   ✓ CNN model has fewer parameters ({cnn_trainable:,} vs {mlp_trainable:,})\")\n",
        "else:\n",
        "    print(f\"   ✓ MLP model has fewer parameters ({mlp_trainable:,} vs {cnn_trainable:,})\")\n",
        "\n",
        "print(\"\\n3. Explain the trade-off between the two models:\")\n",
        "print(\"   ✓ CNN Advantages:\")\n",
        "print(\"     - Better at capturing spatial hierarchies and local patterns\")\n",
        "print(\"     - Parameter sharing reduces overfitting\")\n",
        "print(\"     - Translation invariance (recognizes patterns regardless of position)\")\n",
        "print(\"     - Generally superior for image classification tasks\")\n",
        "print(\"   ✓ MLP Advantages:\")\n",
        "print(\"     - Simpler architecture, easier to implement\")\n",
        "print(\"     - May train faster on some hardware\")\n",
        "print(\"     - Can work well for simpler image tasks\")\n",
        "\n",
        "print(\"\\n4. Why is CNN generally superior for image tasks?\")\n",
        "print(\"   ✓ Convolutional layers preserve spatial relationships\")\n",
        "print(\"   ✓ Hierarchical feature learning (edges → patterns → objects)\")\n",
        "print(\"   ✓ Parameter efficiency through weight sharing\")\n",
        "print(\"   ✓ Built-in translation invariance\")\n",
        "print(\"   ✓ Better generalization with fewer parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOLFbbcvkS71",
        "outputId": "c8336e3f-f81d-4763-e7c1-c6f480d475a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL COMPARISON REPORT\n",
            "================================================================================\n",
            "Model           Test Accuracy   Trainable Parameters Model Size (MB) FLOPs (Training) FLOPs (Inference) Training Memory (MB)\n",
            "MLP             0.8705          235,146              2.72            1,408,512       469,504         2.69           \n",
            "CNN             0.8904          56,714               0.69            339,552         113,184         0.65           \n",
            "\n",
            "================================================================================\n",
            "ANALYSIS AND CONCLUSIONS\n",
            "================================================================================\n",
            "\n",
            "1. Which model achieved a higher accuracy?\n",
            "   ✓ CNN model achieved higher accuracy (0.8904 vs 0.8705)\n",
            "\n",
            "2. Which model had a smaller number of parameters (lower memory footprint)?\n",
            "   ✓ CNN model has fewer parameters (56,714 vs 235,146)\n",
            "\n",
            "3. Explain the trade-off between the two models:\n",
            "   ✓ CNN Advantages:\n",
            "     - Better at capturing spatial hierarchies and local patterns\n",
            "     - Parameter sharing reduces overfitting\n",
            "     - Translation invariance (recognizes patterns regardless of position)\n",
            "     - Generally superior for image classification tasks\n",
            "   ✓ MLP Advantages:\n",
            "     - Simpler architecture, easier to implement\n",
            "     - May train faster on some hardware\n",
            "     - Can work well for simpler image tasks\n",
            "\n",
            "4. Why is CNN generally superior for image tasks?\n",
            "   ✓ Convolutional layers preserve spatial relationships\n",
            "   ✓ Hierarchical feature learning (edges → patterns → objects)\n",
            "   ✓ Parameter efficiency through weight sharing\n",
            "   ✓ Built-in translation invariance\n",
            "   ✓ Better generalization with fewer parameters\n"
          ]
        }
      ]
    }
  ]
}