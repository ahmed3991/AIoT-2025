{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EuKNai1F_3-K"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress TensorFlow logging\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "print(f\"Using TensorFlow version: {tf.__version__}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc4kS94oIPXe",
        "outputId": "4c2b38fa-7595-4428-dcf9-986ea098a28d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow version: 2.19.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup and Data Loading\n",
        "\n",
        "### 1.1. Load the Fashion-MNIST dataset"
      ],
      "metadata": {
        "id": "VOFv76yRIV-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "9XAS-WM8IflJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac224f2-7518-4c23-f733-d9db7b0cba6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Normalize the image data to [0, 1]"
      ],
      "metadata": {
        "id": "YZOh8k7fIrCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "v8DyFNYqI1eb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Reshape data for the CNN (N, 28, 28, 1)\n",
        "\n",
        "We add the 'channels' dimension"
      ],
      "metadata": {
        "id": "PgGK0cYLI0tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_cnn = np.expand_dims(x_train, -1)\n",
        "x_test_cnn = np.expand_dims(x_test, -1)"
      ],
      "metadata": {
        "id": "_e6jij-2JRhI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original x_train shape: {x_train.shape}\")\n",
        "print(f\"Data shape for MLP (no change needed, Flatten layer handles): {x_train.shape}\")\n",
        "print(f\"Data shape for CNN (with channels dim): {x_train_cnn.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6V4ZJjbJY3d",
        "outputId": "a7ddaad2-de1f-4531-ecd9-afc6a9dc84e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original x_train shape: (60000, 28, 28)\n",
            "Data shape for MLP (no change needed, Flatten layer handles): (60000, 28, 28)\n",
            "Data shape for CNN (with channels dim): (60000, 28, 28, 1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Model Implementation\n",
        "\n",
        "### 2.1 MLP model\n",
        "#### 2.1.1 MLP model implementaion"
      ],
      "metadata": {
        "id": "uhqvP82xJnOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "], name=\"MLP_Model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWRAElFFJmPi",
        "outputId": "0e0e18f4-c2c3-41b2-e547-0975c8347997"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 Compile the MLP model"
      ],
      "metadata": {
        "id": "ST4FtJg1JxeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "8ICIK46JJ2DI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3 MLP model summary"
      ],
      "metadata": {
        "id": "D58ENGObJ50x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "_1lLnvsdKAZ9",
        "outputId": "534b6aab-78f6-446d-a01d-a34879f87fdb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"MLP_Model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MLP_Model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 CNN model\n",
        "#### 2.2.1 CNN model implementaion"
      ],
      "metadata": {
        "id": "0C7Mz59IKvdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = keras.Sequential([\n",
        "    # Convolutional Block 1\n",
        "    layers.Conv2D(16, kernel_size=3, activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    # Convolutional Block 2\n",
        "    layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    # Classifier\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "], name=\"CNN_Model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-r0zXwqKuC_",
        "outputId": "5c086cf9-dd46-4249-9c9c-380f093c5806"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 Compile the CNN model"
      ],
      "metadata": {
        "id": "1WgRKyirLvlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "HYxKLRlxLz5t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.3 The CNN model summary"
      ],
      "metadata": {
        "id": "69wfIv_IL3GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "mSyZxgmKL9dy",
        "outputId": "33c62bfb-7491-4a86-beee-78f45437db46"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"CNN_Model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_Model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m51,264\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,714\u001b[0m (221.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,714</span> (221.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,714\u001b[0m (221.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,714</span> (221.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "zWdmsCaNK81Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Training and Evaluation"
      ],
      "metadata": {
        "id": "9AcirbnrMDXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Train MLP model"
      ],
      "metadata": {
        "id": "W9gQB9fDMNg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_history = mlp_model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSBv516BMHUt",
        "outputId": "fac3c88b-74cf-4468-faea-e34cd517eeaa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7817 - loss: 0.6356\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8674 - loss: 0.3630\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8806 - loss: 0.3206\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8898 - loss: 0.2995\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8948 - loss: 0.2866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Train CNN model"
      ],
      "metadata": {
        "id": "jZ6np9PgMXtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_history = cnn_model.fit(\n",
        "    x_train_cnn, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srjPk88AMbGF",
        "outputId": "26ab72be-9d5a-4014-e60a-f9dbb7e53ccb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.7171 - loss: 0.7957\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.8620 - loss: 0.3837\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - accuracy: 0.8798 - loss: 0.3337\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8894 - loss: 0.3053\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 26ms/step - accuracy: 0.8982 - loss: 0.2794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Evaluate and Report\n",
        "\n",
        "#### 3.3.1 MLP model"
      ],
      "metadata": {
        "id": "oc54j9OeMhWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_loss, mlp_acc = mlp_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"MLP Model - Test Loss:     {mlp_loss:.4f}\")\n",
        "print(f\"MLP Model - Test Accuracy: {mlp_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFjoswJUMmAJ",
        "outputId": "63eb0cae-a3cb-4ae0-8639-c1acb83af0f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Model - Test Loss:     0.3526\n",
            "MLP Model - Test Accuracy: 87.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3.2 CNN model"
      ],
      "metadata": {
        "id": "jSUv7U0EMrJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_loss, cnn_acc = cnn_model.evaluate(x_test_cnn, y_test, verbose=0)\n",
        "print(f\"CNN Model - Test Loss:     {cnn_loss:.4f}\")\n",
        "print(f\"CNN Model - Test Accuracy: {cnn_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbHBocvdNApR",
        "outputId": "06710b4e-a7df-438f-ee8c-8bd8c5eca279"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Model - Test Loss:     0.3152\n",
            "CNN Model - Test Accuracy: 88.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Resource Usage Comparison"
      ],
      "metadata": {
        "id": "_R_Tmbj7NJhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_params = mlp_model.count_params()\n",
        "cnn_params = cnn_model.count_params()\n",
        "\n",
        "print(f\"MLP Trainable Parameters: {mlp_params}\")\n",
        "print(f\"CNN Trainable Parameters: {cnn_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn1ddudbNPtV",
        "outputId": "e20b9ed1-4a2f-4c5d-ce10-f7811d972543"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Trainable Parameters: 235146\n",
            "CNN Trainable Parameters: 56714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Save the models"
      ],
      "metadata": {
        "id": "wFbQSFHrNhQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.save('mlp_model.keras')\n",
        "cnn_model.save('cnn_model.keras')"
      ],
      "metadata": {
        "id": "jA2l6sccNs2J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Get file sizes in MB"
      ],
      "metadata": {
        "id": "SHuC_JHQNw9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_size_mb = os.path.getsize('mlp_model.keras') / (1024 * 1024)\n",
        "cnn_size_mb = os.path.getsize('cnn_model.keras') / (1024 * 1024)\n",
        "\n",
        "print(f\"MLP Saved Model Size: {mlp_size_mb:.2f} MB\")\n",
        "print(f\"CNN Saved Model Size: {cnn_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfWu1MYGN0lV",
        "outputId": "43a0fe10-a5cb-46de-a2f0-a3610e6f56f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Saved Model Size: 2.72 MB\n",
            "CNN Saved Model Size: 0.68 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3. Estimate Computational Resources (FLOPs & Training Memory)\n",
        "\n",
        "Calculating exact FLOPs and memory is complex.\n",
        "we gonna use other library to calucalte the FLOPS"
      ],
      "metadata": {
        "id": "xE-Us30iN5Y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.1. FLOPs (Floating-point operations)"
      ],
      "metadata": {
        "id": "EqLg-wCINImB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_count_flops(model, input_shape):\n",
        "    \"\"\"\n",
        "    Counts FLOPs safely across TensorFlow versions.\n",
        "    Uses built-in Model.count_flops() if available (TF ≥ 2.16),\n",
        "    otherwise falls back to a profiler-based method (TF ≤ 2.15).\n",
        "    \"\"\"\n",
        "    # --- Modern API path (TensorFlow 2.16+ / Keras 3.x) ---\n",
        "    if hasattr(model, \"count_flops\"):\n",
        "        flops = model.count_flops(\n",
        "            input_signature=(tf.TensorSpec(shape=(1, *input_shape), dtype=tf.float32),)\n",
        "        )\n",
        "        return flops\n",
        "\n",
        "    # --- Backward-compatible path ---\n",
        "    from tensorflow.python.profiler import model_analyzer, option_builder\n",
        "    from tensorflow.python.framework import convert_to_constants\n",
        "\n",
        "    concrete_func = tf.function(model).get_concrete_function(\n",
        "        tf.TensorSpec([1, *input_shape], tf.float32)\n",
        "    )\n",
        "    frozen_func = convert_to_constants.convert_variables_to_constants_v2(concrete_func)\n",
        "\n",
        "    run_meta = tf.compat.v1.RunMetadata()\n",
        "    opts = option_builder.ProfileOptionBuilder.float_operation()\n",
        "\n",
        "    flops = tf.compat.v1.profiler.profile(\n",
        "        graph=frozen_func.graph,\n",
        "        run_meta=run_meta,\n",
        "        cmd='op',\n",
        "        options=opts\n",
        "    )\n",
        "    return flops.total_float_ops\n",
        "\n",
        "\n",
        "# --- Use it on your models ---\n",
        "mlp_flops = safe_count_flops(mlp_model, input_shape=(28, 28))\n",
        "cnn_flops = safe_count_flops(cnn_model, input_shape=(28, 28, 1))\n",
        "\n",
        "print(f\"MLP Model FLOPs: {mlp_flops / 1e6:.2f} M-FLOPs\")\n",
        "print(f\"CNN Model FLOPs: {cnn_flops / 1e6:.2f} M-FLOPs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc9yxXhUNRbB",
        "outputId": "da45ed1e-7ce1-4494-ae5a-30bd5a436dcc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.12/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:453: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Model FLOPs: 0.47 M-FLOPs\n",
            "CNN Model FLOPs: 1.44 M-FLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.2. Training Memory\n",
        "\n",
        "Training memory ≈ (Model Parameters + Gradients + Optimizer State) + Activations\n",
        "- Model Parameters: Size of weights (e.g., mlp_params \\* 4 bytes for float32)\n",
        "- Gradients: Same size as parameters.\n",
        "- Optimizer State: For Adam, stores 2 states (m, v) per param. (2 \\* param_size)\n",
        "- Activations: Depends on batch_size. (batch_size \\* activation_size_per_layer)\n",
        "\n",
        "Rough Estimate (Model-related memory, excluding activations):\n",
        "Total = Params + Gradients + Optimizer(m) + Optimizer(v) = 4 \\* Param_size"
      ],
      "metadata": {
        "id": "xiJm042TOILo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_train_mem_mb = (mlp_params * 4 * 4) / (1024 * 1024) # 4x params, 4 bytes/param\n",
        "cnn_train_mem_mb = (cnn_params * 4 * 4) / (1024 * 1024) # 4x params, 4 bytes/param\n",
        "print(f\"Estimated MLP Training Memory (Params + Grads + Adam): {mlp_train_mem_mb:.2f} MB\")\n",
        "print(f\"Estimated CNN Training Memory (Params + Grads + Adam): {cnn_train_mem_mb:.2f} MB\")\n",
        "print(\"(This excludes memory for batch activations, which can be significant)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr3B5g6sOmvT",
        "outputId": "226da362-4174-4e8d-dc1b-aa478de75211"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated MLP Training Memory (Params + Grads + Adam): 3.59 MB\n",
            "Estimated CNN Training Memory (Params + Grads + Adam): 0.87 MB\n",
            "(This excludes memory for batch activations, which can be significant)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Final Report and Conclusion"
      ],
      "metadata": {
        "id": "lRW0sVtXOxfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Write the Conclusion\n",
        "\n",
        "create a model summary"
      ],
      "metadata": {
        "id": "4p7Yk-uYO4K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_data = {\n",
        "    \"Model\": [\"MLP\", \"CNN\"],\n",
        "    \"Test Accuracy\": [f\"{mlp_acc*100:.2f}%\", f\"{cnn_acc*100:.2f}%\"],\n",
        "    \"Trainable Parameters\": [mlp_params, cnn_params],\n",
        "    \"Saved Model Size (MB)\": [f\"{mlp_size_mb:.2f}\", f\"{cnn_size_mb:.2f}\"],\n",
        "    \"FLOPs (Inference)\": [\"0.47 M-FLOPs\", \"1.44 M-FLOPs\"],\n",
        "    \"FLOPs (Training)\": [\"~1.4 MFLOPs (Est.)\", \"~4.24 MFLOPs (Est.)\"],\n",
        "    \"Training Memory (MB)\": [f\"~{mlp_train_mem_mb:.2f} + Activations\", f\"~{cnn_train_mem_mb:.2f} + Activations\"]\n",
        "}\n",
        "\n",
        "summary_table = pd.DataFrame(summary_data)\n",
        "print(summary_table.to_markdown(index=False, numalign=\"center\", stralign=\"center\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19gqxkz2O_yx",
        "outputId": "1347fb6e-73eb-4dac-e2c4-5b95eb1d356c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|  Model  |  Test Accuracy  |  Trainable Parameters  |  Saved Model Size (MB)  |  FLOPs (Inference)  |  FLOPs (Training)   |  Training Memory (MB)  |\n",
            "|:-------:|:---------------:|:----------------------:|:-----------------------:|:-------------------:|:-------------------:|:----------------------:|\n",
            "|   MLP   |     87.73%      |         235146         |          2.72           |    0.47 M-FLOPs     | ~1.4 MFLOPs (Est.)  |  ~3.59 + Activations   |\n",
            "|   CNN   |     88.42%      |         56714          |          0.68           |    1.44 M-FLOPs     | ~4.24 MFLOPs (Est.) |  ~0.87 + Activations   |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|  Model  |  Test Accuracy  |  Trainable Parameters  |  Saved Model Size (MB)  |  FLOPs (Inference)  |  FLOPs (Training)  |  Training Memory (MB)  |\n",
        "|:-------:|:---------------:|:----------------------:|:-----------------------:|:-------------------:|:------------------:|:----------------------:|\n",
        "|   MLP   |     88.17%      |         235146         |          2.72           | ~470 kFLOPs (Est.)  | ~1.4 MFLOPs (Est.) |  ~3.59 + Activations   |\n",
        "|   CNN   |     88.98%      |         56714          |          0.69           | ~1.2 MFLOPs (Est.)  | ~3.6 MFLOPs (Est.) |  ~0.87 + Activations   |"
      ],
      "metadata": {
        "id": "lfxT4PymS-_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion Questions"
      ],
      "metadata": {
        "id": "SRfViSOdPS-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which model achieved a higher accuracy?\n",
        "\n",
        "Answer: The **CNN model** achieved higher accuracy (88.98%) compared to the MLP model (88.17%)."
      ],
      "metadata": {
        "id": "8XNQGHBzPWzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which model had a smaller number of parameters (lower memory footprint)?\n",
        "Answer: The **CNN model** had significantly fewer parameters (56714) than the MLP model (235146). This also resulted in a smaller saved file size.\n"
      ],
      "metadata": {
        "id": "iZCEZ7kBPqfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the trade-off between the two models...\n",
        "\n",
        "The **CNN model** (the \"winner\" in accuracy) is superior for image tasks because it uses **convolutional layers**. These layers are specifically designed to find spatial patterns (like edges, textures, and shapes) in the image. They also use **parameter sharing**, where the same filter (kernel) is slid across the entire image. This makes the model:\n",
        "   1.  **More effective:** It learns features that are *translationally invariant* (it can find a \"shoe\" anywhere in the image).\n",
        "   2.  **More efficient:** It needs far fewer parameters than an MLP, which connects *every* input pixel to *every* neuron in the first hidden layer.\n",
        "\n",
        "\n",
        "The **MLP model**'s main disadvantage is that it's \"fully connected.\" It treats the $28 \\times 28$ image as a flat $784$-element vector and loses all spatial information. It doesn't know which pixels are next to each other. Its only \"advantage\" in this context is its conceptual simplicity, but it is a poor choice for image data, as shown by its lower accuracy and massive parameter count.\n",
        "\n",
        "\n",
        "**In summary:** The CNN achieves higher accuracy with *fewer* parameters because it is an architecture fundamentally suited for spatial data like images."
      ],
      "metadata": {
        "id": "3SYbUXmoPxgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Lab 6\n",
        "\n",
        "### 6.1 Loading keras models"
      ],
      "metadata": {
        "id": "fkXlnNHMHEJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = tf.keras.models.load_model('mlp_model.keras')\n",
        "cnn_model = tf.keras.models.load_model('cnn_model.keras')"
      ],
      "metadata": {
        "id": "CEVzN_1pG_jX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. Load and Prepare the Representative Dataset\n",
        "This is required for Full Integer Quantization\n",
        "We only need a small sample of the training data for calibration."
      ],
      "metadata": {
        "id": "NoSCavHAHonP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "HoswWzPhIOi4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Representative data for MLP (input shape 28, 28)\n",
        "rep_data_mlp = x_train[:300] # 300 samples is plenty"
      ],
      "metadata": {
        "id": "zAgrxJTPITLI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Representative data for CNN (input shape 28, 28, 1)\n",
        "x_train_cnn = np.expand_dims(x_train, -1)\n",
        "rep_data_cnn = x_train_cnn[:300] # 300 samples"
      ],
      "metadata": {
        "id": "jspLwTrWI-0A"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Using {len(rep_data_mlp)} samples for calibration.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HosvFthWJDyn",
        "outputId": "1ceed6b4-3c5e-4c5c-e5fe-fbc1dcf26b7f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 300 samples for calibration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3. Define the Representative Dataset Generator"
      ],
      "metadata": {
        "id": "vnPXo-uAJMXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_dataset_gen(data):\n",
        "    def gen():\n",
        "        for image in data:\n",
        "            # Yield the image, cast to float32, and add a batch dimension\n",
        "            yield [np.expand_dims(image, axis=0).astype(np.float32)]\n",
        "    return gen"
      ],
      "metadata": {
        "id": "Cq39S_ulJMA-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4. Task 3.1: Convert and Quantize MLP Model"
      ],
      "metadata": {
        "id": "F8-XIIi9JdnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the generator for the MLP data\n",
        "mlp_rep_gen = representative_dataset_gen(rep_data_mlp)\n",
        "\n",
        "converter_mlp = tf.lite.TFLiteConverter.from_keras_model(mlp_model)\n",
        "converter_mlp.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_mlp.representative_dataset = mlp_rep_gen\n",
        "# Enforce full integer quantization for microcontroller compatibility\n",
        "converter_mlp.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter_mlp.inference_input_type = tf.uint8  # Input will be 0-255 images\n",
        "converter_mlp.inference_output_type = tf.uint8 # Output will be quantized scores\n",
        "\n",
        "tflite_model_quant_mlp = converter_mlp.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "with open('mlp_model_quant_int8.tflite', 'wb') as f:\n",
        "    f.write(tflite_model_quant_mlp)\n",
        "\n",
        "print(\"MLP TFLite model converted and saved as 'mlp_model_quant_int8.tflite'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRH4y2iZJmxp",
        "outputId": "204aa5fc-2791-4582-858b-84ac2e018609"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpylbg00xa'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132545097605264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545097613136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545097598544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545097612176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545097601040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545097605648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP TFLite model converted and saved as 'mlp_model_quant_int8.tflite'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5. Task 3.2: Convert and Quantize CNN Model"
      ],
      "metadata": {
        "id": "AxS_ZiVqJrTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the generator for the CNN data\n",
        "cnn_rep_gen = representative_dataset_gen(rep_data_cnn)\n",
        "\n",
        "converter_cnn = tf.lite.TFLiteConverter.from_keras_model(cnn_model)\n",
        "converter_cnn.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_cnn.representative_dataset = cnn_rep_gen\n",
        "# Enforce full integer quantization\n",
        "converter_cnn.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter_cnn.inference_input_type = tf.uint8\n",
        "converter_cnn.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model_quant_cnn = converter_cnn.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "with open('cnn_model_quant_int8.tflite', 'wb') as f:\n",
        "    f.write(tflite_model_quant_cnn)\n",
        "\n",
        "print(\"CNN TFLite model converted and saved as 'cnn_model_quant_int8.tflite'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXEhyrYjKhP6",
        "outputId": "5af3102f-0503-48cf-f565-25690edad444"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpt1z1g43s'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_layer_1')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132545086198928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545086199696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545086202960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545086202000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545086199888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545086203152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545086202576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132545086203536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN TFLite model converted and saved as 'cnn_model_quant_int8.tflite'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.6. Task 4.1: Report File Sizes"
      ],
      "metadata": {
        "id": "EMBdkRyQK1Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get original Keras model sizes\n",
        "mlp_keras_size_kb = os.path.getsize('mlp_model.keras') / 1024\n",
        "cnn_keras_size_kb = os.path.getsize('cnn_model.keras') / 1024"
      ],
      "metadata": {
        "id": "NRRzKRcvK90O"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get new TFLite model sizes\n",
        "mlp_tflite_size_kb = os.path.getsize('mlp_model_quant_int8.tflite') / 1024\n",
        "cnn_tflite_size_kb = os.path.getsize('cnn_model_quant_int8.tflite') / 1024"
      ],
      "metadata": {
        "id": "5tfU-IqvLDbi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nOriginal Keras Models (float32):\")\n",
        "print(f\"  MLP Keras Size: {mlp_keras_size_kb:.2f} KB ({mlp_keras_size_kb/1024:.2f} MB)\")\n",
        "print(f\"  CNN Keras Size: {cnn_keras_size_kb:.2f} KB ({cnn_keras_size_kb/1024:.2f} MB)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ExrzM1LFXb",
        "outputId": "159fb477-6c6a-45db-c179-91f7a9a22b6b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Keras Models (float32):\n",
            "  MLP Keras Size: 2782.62 KB (2.72 MB)\n",
            "  CNN Keras Size: 701.13 KB (0.68 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nQuantized TFLite Models (int8):\")\n",
        "print(f\"  MLP TFLite Size:  {mlp_tflite_size_kb:.2f} KB\")\n",
        "print(f\"  CNN TFLite Size:  {cnn_tflite_size_kb:.2f} KB\")\n",
        "\n",
        "print(\"\\nConstraint:\")\n",
        "print(f\"  XIAO ESP32S3 SRAM: 512 KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoGI2gwSLBrf",
        "outputId": "c1e911f5-cfc7-4d28-f95e-088bd3af0cc0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Quantized TFLite Models (int8):\n",
            "  MLP TFLite Size:  243.04 KB\n",
            "  CNN TFLite Size:  62.77 KB\n",
            "\n",
            "Constraint:\n",
            "  XIAO ESP32S3 SRAM: 512 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model | Keras Size (Float32, MB) | Quantized TFLite Size (int8, MB) | SRAM Constraint (XIAO) | Can Model Fit in SRAM? |\n",
        "|--------|---------------------------|----------------------------------|------------------------|------------------------|\n",
        "| MLP    | ≈0.9                     | ≈0.24 MB (243.04 KB)            | 512 KB (0.5 MB)        | Yes                    |\n",
        "| CNN    | ≈0.2                     | ≈0.06 MB (62.77 KB)             | 512 KB (0.5 MB)        | Yes                    |\n"
      ],
      "metadata": {
        "id": "5B_df8UPNFID"
      }
    }
  ]
}