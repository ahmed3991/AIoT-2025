{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq8bfBO3AjF2YLk5Vy24pN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikramyoumba1/AIoT-2025/blob/main/TP6_AIoT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a727TZmkB33t"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fashion-MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGioQOdPHh09",
        "outputId": "48f48f86-8da2-462e-c1ff-ed8433ec50de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "v_p9JDW1HqZH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for MLP (flattened)\n",
        "x_train_mlp = x_train.reshape(x_train.shape[0], 28, 28)\n",
        "x_test_mlp = x_test.reshape(x_test.shape[0], 28, 28)"
      ],
      "metadata": {
        "id": "PZo8Nl78Hwel"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for CNN (add channel dimension)\n",
        "x_train_cnn = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test_cnn = x_test.reshape(x_test.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "eeYv_Qs7H1kW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset shapes:\")\n",
        "print(f\"Original train images: {x_train.shape}\")\n",
        "print(f\"MLP train images: {x_train_mlp.shape}\")\n",
        "print(f\"CNN train images: {x_train_cnn.shape}\")\n",
        "print(f\"Train labels: {y_train.shape}\")\n",
        "print(f\"Test images: {x_test.shape}\")\n",
        "print(f\"Test labels: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQqTSczWH8lH",
        "outputId": "f02b2689-f84c-4e12-9e52-67dc9256f8d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shapes:\n",
            "Original train images: (60000, 28, 28)\n",
            "MLP train images: (60000, 28, 28)\n",
            "CNN train images: (60000, 28, 28, 1)\n",
            "Train labels: (60000,)\n",
            "Test images: (10000, 28, 28)\n",
            "Test labels: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"# Task 2.1: Implement and Compile the MLP Model\"\"\"\n"
      ],
      "metadata": {
        "id": "Pt4UXwXyH-Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K_ZddfLICf9",
        "outputId": "979dc24d-dc1c-4ec9-8854-5854c6cde979"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "2tQQBX93IGLe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MLP Model Summary:\")\n",
        "print(\"=\"*50)\n",
        "mlp_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "j1OxCvMLIMKF",
        "outputId": "c74d148b-456e-40ba-c608-af1fc746debd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MLP Model Summary:\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"# Task 2.2: Implement and Compile the CNN Model\"\"\""
      ],
      "metadata": {
        "id": "pI2lp5pNIZBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eHvrMwFIYzi",
        "outputId": "d74fbc1c-1afd-4a0c-cc4e-084954f62d36"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "_zt3GK7LIg7s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CNN Model Summary:\")\n",
        "print(\"=\"*50)\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "xT10eq_oIlnW",
        "outputId": "1e9327d4-a466-421c-8de1-f60d02336d60"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "CNN Model Summary:\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m51,264\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,714\u001b[0m (221.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,714</span> (221.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,714\u001b[0m (221.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,714</span> (221.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"# Task 3.1: Train the MLP\"\"\""
      ],
      "metadata": {
        "id": "7n-_tK8mIpFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training MLP Model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "history_mlp = mlp_model.fit(\n",
        "    x_train_mlp, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    validation_data=(x_test_mlp, y_test),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TVVL9rsIqOK",
        "outputId": "435ba9a1-163c-4466-8fac-b25e59bd0374"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training MLP Model...\n",
            "==================================================\n",
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7761 - loss: 0.6372 - val_accuracy: 0.8485 - val_loss: 0.4100\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8666 - loss: 0.3680 - val_accuracy: 0.8497 - val_loss: 0.4096\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8785 - loss: 0.3288 - val_accuracy: 0.8615 - val_loss: 0.3699\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.8894 - loss: 0.2985 - val_accuracy: 0.8599 - val_loss: 0.3771\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8954 - loss: 0.2814 - val_accuracy: 0.8794 - val_loss: 0.3416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"# Task 3.2: Train the CNN\"\"\""
      ],
      "metadata": {
        "id": "y2Uk95pAI02C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training CNN Model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "history_cnn = cnn_model.fit(\n",
        "    x_train_cnn, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    validation_data=(x_test_cnn, y_test),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrsBxJxgI1oE",
        "outputId": "27e9ba6e-bc18-4589-9772-47e8c2fd8b8e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training CNN Model...\n",
            "==================================================\n",
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.7298 - loss: 0.7760 - val_accuracy: 0.8360 - val_loss: 0.4478\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.8650 - loss: 0.3690 - val_accuracy: 0.8706 - val_loss: 0.3671\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 43ms/step - accuracy: 0.8852 - loss: 0.3168 - val_accuracy: 0.8680 - val_loss: 0.3591\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.8920 - loss: 0.2936 - val_accuracy: 0.8862 - val_loss: 0.3184\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8999 - loss: 0.2711 - val_accuracy: 0.8908 - val_loss: 0.3027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"# Task 3.3: Evaluate and Report\"\"\""
      ],
      "metadata": {
        "id": "yEyQhQ50I-v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Model Evaluation Results:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Evaluate MLP\n",
        "test_loss_mlp, test_accuracy_mlp = mlp_model.evaluate(x_test_mlp, y_test, verbose=0)\n",
        "print(f\"MLP Model - Test Loss: {test_loss_mlp:.4f}, Test Accuracy: {test_accuracy_mlp:.4f}\")\n",
        "\n",
        "# Evaluate CNN\n",
        "test_loss_cnn, test_accuracy_cnn = cnn_model.evaluate(x_test_cnn, y_test, verbose=0)\n",
        "print(f\"CNN Model - Test Loss: {test_loss_cnn:.4f}, Test Accuracy: {test_accuracy_cnn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK4mZes-I_9K",
        "outputId": "f02283e0-ad27-42d4-8167-f4094afb2350"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Model Evaluation Results:\n",
            "==================================================\n",
            "MLP Model - Test Loss: 0.3416, Test Accuracy: 0.8794\n",
            "CNN Model - Test Loss: 0.3027, Test Accuracy: 0.8908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"# Task 4.1: Count Trainable Parameters\"\"\""
      ],
      "metadata": {
        "id": "5ArepqFvJHZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
        "    non_trainable_params = np.sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
        "    return trainable_params, non_trainable_params\n",
        "\n",
        "mlp_trainable, mlp_non_trainable = count_parameters(mlp_model)\n",
        "cnn_trainable, cnn_non_trainable = count_parameters(cnn_model)\n",
        "\n",
        "print(f\"\\nMLP Trainable Parameters: {mlp_trainable:,}\")\n",
        "print(f\"CNN Trainable Parameters: {cnn_trainable:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gDP0LMwJLej",
        "outputId": "6fb708d1-f8a1-4cb3-903a-c26f6fd70357"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP Trainable Parameters: 235,146\n",
            "CNN Trainable Parameters: 56,714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"# Task 4.2: Estimate Memory Footprint\"\"\""
      ],
      "metadata": {
        "id": "XddFHqVxJSpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "mlp_model.save('mlp_model.h5')\n",
        "cnn_model.save('cnn_model.h5')\n",
        "\n",
        "# Get file sizes\n",
        "mlp_size = os.path.getsize('mlp_model.h5') / (1024 * 1024)  # Convert to MB\n",
        "cnn_size = os.path.getsize('cnn_model.h5') / (1024 * 1024)  # Convert to MB\n",
        "\n",
        "print(f\"\\nMLP Model Size: {mlp_size:.2f} MB\")\n",
        "print(f\"CNN Model Size: {cnn_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMrykC0hJT7L",
        "outputId": "4277aa4e-90d2-4541-e72b-79b2fbee23cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP Model Size: 2.72 MB\n",
            "CNN Model Size: 0.69 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"# Task 4.3: Estimate Computational Resources\"\"\""
      ],
      "metadata": {
        "id": "rFiteTsFJgdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_flops_and_memory(model, input_shape, batch_size=64):\n",
        "\n",
        "    # Count total parameters\n",
        "    total_params = sum([np.prod(layer.get_weights()[0].shape) if layer.get_weights() else 0\n",
        "                       for layer in model.layers])\n",
        "\n",
        "\n",
        "    # This varies by layer type but we use a rough estimate\n",
        "    inference_flops = total_params * 2\n",
        "    training_flops = inference_flops * 3\n",
        "\n",
        "    # Memory estimation (parameters + gradients + optimizer state)\n",
        "    param_memory = total_params * 4 / (1024 * 1024)\n",
        "    training_memory = param_memory * 3\n",
        "\n",
        "    return inference_flops, training_flops, training_memory\n",
        "\n",
        "# Estimate for MLP\n",
        "mlp_inf_flops, mlp_train_flops, mlp_train_mem = estimate_flops_and_memory(mlp_model, (28, 28))\n",
        "\n",
        "# Estimate for CNN\n",
        "cnn_inf_flops, cnn_train_flops, cnn_train_mem = estimate_flops_and_memory(cnn_model, (28, 28, 1))\n",
        "\n",
        "print(f\"\\nComputational Resources Estimation:\")\n",
        "print(f\"MLP - Inference FLOPs: {mlp_inf_flops:,.0f}, Training FLOPs: {mlp_train_flops:,.0f}, Training Memory: {mlp_train_mem:.2f} MB\")\n",
        "print(f\"CNN - Inference FLOPs: {cnn_inf_flops:,.0f}, Training FLOPs: {cnn_train_flops:,.0f}, Training Memory: {cnn_train_mem:.2f} MB\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOxZwG4bJhTq",
        "outputId": "e173f7c9-540d-420c-b721-aa9c6310e6be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computational Resources Estimation:\n",
            "MLP - Inference FLOPs: 469,504, Training FLOPs: 1,408,512, Training Memory: 2.69 MB\n",
            "CNN - Inference FLOPs: 113,184, Training FLOPs: 339,552, Training Memory: 0.65 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3.1: Convert and Quantize the MLP Model\n"
      ],
      "metadata": {
        "id": "2ONfkew8KAxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TENSORFLOW LITE CONVERSION - MLP MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def representative_data_gen_mlp():\n",
        "    for i in range(100):\n",
        "        yield [x_train_mlp[i:i+1].astype(np.float32)]\n",
        "\n",
        "# Convert MLP model to TFLite with full integer quantization\n",
        "converter_mlp = tf.lite.TFLiteConverter.from_keras_model(mlp_model)\n",
        "converter_mlp.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_mlp.representative_dataset = representative_data_gen_mlp\n",
        "converter_mlp.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter_mlp.inference_input_type = tf.int8\n",
        "converter_mlp.inference_output_type = tf.int8\n",
        "\n",
        "tflite_mlp_model = converter_mlp.convert()\n",
        "\n",
        "# Save the quantized MLP model\n",
        "with open('mlp_model_quantized.tflite', 'wb') as f:\n",
        "    f.write(tflite_mlp_model)\n",
        "\n",
        "mlp_tflite_size = os.path.getsize('mlp_model_quantized.tflite') / (1024 * 1024)  # Convert to MB\n",
        "print(f\"MLP Model - Original Keras Size: {mlp_size:.2f} MB\")\n",
        "print(f\"MLP Model - Quantized TFLite Size: {mlp_tflite_size:.2f} MB\")\n",
        "print(f\"Size Reduction: {(mlp_size - mlp_tflite_size):.2f} MB ({((mlp_size - mlp_tflite_size)/mlp_size)*100:.1f}% reduction)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmOzoNPyKCP0",
        "outputId": "42b82340-6f96-4400-fbe0-b0974c1726ac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TENSORFLOW LITE CONVERSION - MLP MODEL\n",
            "============================================================\n",
            "Saved artifact at '/tmp/tmp86jw7e7w'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133339698882960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698883920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698883344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698883728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698884112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698882192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Model - Original Keras Size: 2.72 MB\n",
            "MLP Model - Quantized TFLite Size: 0.24 MB\n",
            "Size Reduction: 2.48 MB (91.3% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"## Task 3.2: Convert and Quantize the CNN Model\"\"\""
      ],
      "metadata": {
        "id": "z5DXBMK_KSha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TENSORFLOW LITE CONVERSION - CNN MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def representative_data_gen_cnn():\n",
        "    for i in range(100):\n",
        "        yield [x_train_cnn[i:i+1].astype(np.float32)]\n",
        "\n",
        "# Convert CNN model to TFLite with full integer quantization\n",
        "converter_cnn = tf.lite.TFLiteConverter.from_keras_model(cnn_model)\n",
        "converter_cnn.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_cnn.representative_dataset = representative_data_gen_cnn\n",
        "converter_cnn.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter_cnn.inference_input_type = tf.int8\n",
        "converter_cnn.inference_output_type = tf.int8\n",
        "\n",
        "tflite_cnn_model = converter_cnn.convert()\n",
        "\n",
        "# Save the quantized CNN model\n",
        "with open('cnn_model_quantized.tflite', 'wb') as f:\n",
        "    f.write(tflite_cnn_model)\n",
        "\n",
        "cnn_tflite_size = os.path.getsize('cnn_model_quantized.tflite') / (1024 * 1024)  # Convert to MB\n",
        "print(f\"CNN Model - Original Keras Size: {cnn_size:.2f} MB\")\n",
        "print(f\"CNN Model - Quantized TFLite Size: {cnn_tflite_size:.2f} MB\")\n",
        "print(f\"Size Reduction: {(cnn_size - cnn_tflite_size):.2f} MB ({((cnn_size - cnn_tflite_size)/cnn_size)*100:.1f}% reduction)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqZGMXMkKUe2",
        "outputId": "22307262-7bef-4ce0-e968-981b1262614c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TENSORFLOW LITE CONVERSION - CNN MODEL\n",
            "============================================================\n",
            "Saved artifact at '/tmp/tmpj45mdjrf'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor_5')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133339698887184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698887952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698887568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698888528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698887376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339698886992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339694220304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133339694219920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "CNN Model - Original Keras Size: 0.69 MB\n",
            "CNN Model - Quantized TFLite Size: 0.06 MB\n",
            "Size Reduction: 0.63 MB (91.1% reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"## Task 4.1: Model Size Comparison Table\"\"\""
      ],
      "metadata": {
        "id": "P5KoB0UTKhPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DEPLOYMENT FEASIBILITY ANALYSIS - XIAO ESP32S3\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert sizes to KB for comparison with SRAM constraint\n",
        "mlp_tflite_size_kb = mlp_tflite_size * 1024\n",
        "cnn_tflite_size_kb = cnn_tflite_size * 1024\n",
        "xiao_sram_kb = 512  # 512 KB SRAM\n",
        "\n",
        "print(\"\\nModel Size Comparison Table:\")\n",
        "print(\"| Model | Keras Size (Float32, MB) | Quantized TFLite Size (int8, MB) | TFLite Size (KB) | SRAM Constraint (XIAO) | Can Model Fit in SRAM? |\")\n",
        "print(\"|-------|--------------------------|----------------------------------|------------------|------------------------|------------------------|\")\n",
        "print(f\"| MLP   | {mlp_size:.2f} MB                | {mlp_tflite_size:.2f} MB                        | {mlp_tflite_size_kb:.1f} KB       | 512 KB                 | {'YES' if mlp_tflite_size_kb < xiao_sram_kb else 'NO'}                    |\")\n",
        "print(f\"| CNN   | {cnn_size:.2f} MB                | {cnn_tflite_size:.2f} MB                        | {cnn_tflite_size_kb:.1f} KB       | 512 KB                 | {'YES' if cnn_tflite_size_kb < xiao_sram_kb else 'NO'}                    |\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR-4tDB0KlHE",
        "outputId": "50a3d5c1-a322-4220-fda9-58657662e41d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DEPLOYMENT FEASIBILITY ANALYSIS - XIAO ESP32S3\n",
            "================================================================================\n",
            "\n",
            "Model Size Comparison Table:\n",
            "| Model | Keras Size (Float32, MB) | Quantized TFLite Size (int8, MB) | TFLite Size (KB) | SRAM Constraint (XIAO) | Can Model Fit in SRAM? |\n",
            "|-------|--------------------------|----------------------------------|------------------|------------------------|------------------------|\n",
            "| MLP   | 2.72 MB                | 0.24 MB                        | 242.7 KB       | 512 KB                 | YES                    |\n",
            "| CNN   | 0.69 MB                | 0.06 MB                        | 62.4 KB       | 512 KB                 | YES                    |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"## Task 4.2: TFLite Model Accuracy Validation\"\"\""
      ],
      "metadata": {
        "id": "pKTqO2jaLBwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TFLITE MODEL ACCURACY VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Function to evaluate TFLite model\n",
        "def evaluate_tflite_model(tflite_model_path, x_test, y_test):\n",
        "    # Load TFLite model and allocate tensors\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Run predictions\n",
        "    predictions = []\n",
        "    for i in range(len(x_test)):\n",
        "        # Preprocess input based on model requirements\n",
        "        if input_details[0]['dtype'] == np.int8:\n",
        "            input_data = (x_test[i:i+1] * 255).astype(np.int8)\n",
        "        else:\n",
        "            input_data = x_test[i:i+1].astype(np.float32)\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        predictions.append(np.argmax(output))\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = np.mean(np.array(predictions) == y_test[:len(predictions)])\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate MLP TFLite model\n",
        "print(\"Evaluating MLP TFLite model...\")\n",
        "mlp_tflite_accuracy = evaluate_tflite_model('mlp_model_quantized.tflite', x_test_mlp, y_test)\n",
        "print(f\"MLP TFLite Model Accuracy: {mlp_tflite_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate CNN TFLite model\n",
        "print(\"Evaluating CNN TFLite model...\")\n",
        "cnn_tflite_accuracy = evaluate_tflite_model('cnn_model_quantized.tflite', x_test_cnn, y_test)\n",
        "print(f\"CNN TFLite Model Accuracy: {cnn_tflite_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nAccuracy Comparison:\")\n",
        "print(f\"Original MLP Accuracy: {test_accuracy_mlp:.4f}, TFLite MLP Accuracy: {mlp_tflite_accuracy:.4f}\")\n",
        "print(f\"Original CNN Accuracy: {test_accuracy_cnn:.4f}, TFLite CNN Accuracy: {cnn_tflite_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "102TID18LCqW",
        "outputId": "1b21199d-5116-4584-9ad3-30266c398ab1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TFLITE MODEL ACCURACY VALIDATION\n",
            "============================================================\n",
            "Evaluating MLP TFLite model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP TFLite Model Accuracy: 0.0927\n",
            "Evaluating CNN TFLite model...\n",
            "CNN TFLite Model Accuracy: 0.2507\n",
            "\n",
            "Accuracy Comparison:\n",
            "Original MLP Accuracy: 0.8794, TFLite MLP Accuracy: 0.0927\n",
            "Original CNN Accuracy: 0.8908, TFLite CNN Accuracy: 0.2507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"## Task 4.3: Conclusion on XIAO Deployment\"\"\""
      ],
      "metadata": {
        "id": "ZGVo0D3KLQnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL DEPLOYMENT CONCLUSION - XIAO ESP32S3\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n📝 Task 1.1: Seeed Studio XIAO ESP32S3 Specifications Analysis\")\n",
        "print(\"The XIAO ESP32S3 is suitable for TinyML deployment due to:\")\n",
        "print(\"✓ Dual-core LX7 processor @ 240 MHz - Provides adequate computational power\")\n",
        "print(\"✓ 512 KB SRAM - Critical constraint for model deployment\")\n",
        "print(\"✓ 8 MB PSRAM / 16 MB Flash - Ample storage for models and code\")\n",
        "print(\"✓ Low-power modes - Essential for battery-operated IoT applications\")\n",
        "\n",
        "print(\"\\n📝 Task 2.1: The Role of TensorFlow Lite (TFLite)\")\n",
        "print(\"TFLite is essential because:\")\n",
        "print(\"✓ Converts large Keras models to optimized .tflite format\")\n",
        "print(\"✓ Provides specialized runtime for resource-constrained devices\")\n",
        "print(\"✓ Reduces memory footprint and improves inference speed\")\n",
        "\n",
        "print(\"\\n📝 Task 2.2: The Need for Quantization\")\n",
        "print(\"Quantization benefits:\")\n",
        "print(\"✓ Reduces model size by ~75% (float32 → int8)\")\n",
        "print(\"✓ Improves inference speed (integer operations are faster)\")\n",
        "print(\"✓ Reduces power consumption\")\n",
        "print(\"✓ Minimal accuracy loss for significant gains\")\n",
        "\n",
        "print(\"\\n🚀 DEPLOYMENT FEASIBILITY ASSESSMENT:\")\n",
        "\n",
        "# Memory constraint analysis\n",
        "print(f\"\\n1. MEMORY CONSTRAINT ANALYSIS:\")\n",
        "print(f\"   XIAO ESP32S3 SRAM: {xiao_sram_kb} KB\")\n",
        "print(f\"   MLP TFLite Size: {mlp_tflite_size_kb:.1f} KB → {'✓ FITS' if mlp_tflite_size_kb < xiao_sram_kb else '✗ TOO LARGE'}\")\n",
        "print(f\"   CNN TFLite Size: {cnn_tflite_size_kb:.1f} KB → {'✓ FITS' if cnn_tflite_size_kb < xiao_sram_kb else '✗ TOO LARGE'}\")\n",
        "\n",
        "# Performance analysis\n",
        "print(f\"\\n2. PERFORMANCE ANALYSIS:\")\n",
        "print(f\"   Processor: Dual-core 240 MHz LX7\")\n",
        "estimated_inference_time_mlp = (mlp_trainable / 1000000) * 10  # Rough estimate\n",
        "estimated_inference_time_cnn = (cnn_trainable / 1000000) * 5   # Rough estimate\n",
        "print(f\"   Estimated MLP Inference Time: ~{estimated_inference_time_mlp:.1f} ms\")\n",
        "print(f\"   Estimated CNN Inference Time: ~{estimated_inference_time_cnn:.1f} ms\")\n",
        "print(f\"   Real-time requirement: < 100 ms → {'✓ FEASIBLE' if estimated_inference_time_mlp < 100 and estimated_inference_time_cnn < 100 else '✗ MARGINAL'}\")\n",
        "\n",
        "# Accuracy analysis\n",
        "print(f\"\\n3. ACCURACY ANALYSIS:\")\n",
        "print(f\"   MLP Accuracy: Original={test_accuracy_mlp:.4f}, TFLite={mlp_tflite_accuracy:.4f}\")\n",
        "print(f\"   CNN Accuracy: Original={test_accuracy_cnn:.4f}, TFLite={cnn_tflite_accuracy:.4f}\")\n",
        "print(f\"   Accuracy loss: MLP={((test_accuracy_mlp-mlp_tflite_accuracy)/test_accuracy_mlp*100):.2f}%, CNN={((test_accuracy_cnn-cnn_tflite_accuracy)/test_accuracy_cnn*100):.2f}%\")\n",
        "\n",
        "print(f\"\\n🎯 FINAL DEPLOYMENT RECOMMENDATION:\")\n",
        "if mlp_tflite_size_kb < xiao_sram_kb and cnn_tflite_size_kb < xiao_sram_kb:\n",
        "    print(\"✓ BOTH models can be deployed on XIAO ESP32S3\")\n",
        "    print(\"✓ Recommended model: CNN (better accuracy with smaller size)\")\n",
        "elif cnn_tflite_size_kb < xiao_sram_kb:\n",
        "    print(\"✓ CNN model can be deployed on XIAO ESP32S3\")\n",
        "    print(\"✗ MLP model is too large for deployment\")\n",
        "else:\n",
        "    print(\"✗ BOTH models require further optimization for XIAO ESP32S3 deployment\")\n",
        "    print(\"  Consider: Pruning, more aggressive quantization, or model architecture changes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHVcEKvWLUgG",
        "outputId": "f6068345-9bea-4384-b81a-a5b7151c607b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL DEPLOYMENT CONCLUSION - XIAO ESP32S3\n",
            "================================================================================\n",
            "\n",
            "📝 Task 1.1: Seeed Studio XIAO ESP32S3 Specifications Analysis\n",
            "The XIAO ESP32S3 is suitable for TinyML deployment due to:\n",
            "✓ Dual-core LX7 processor @ 240 MHz - Provides adequate computational power\n",
            "✓ 512 KB SRAM - Critical constraint for model deployment\n",
            "✓ 8 MB PSRAM / 16 MB Flash - Ample storage for models and code\n",
            "✓ Low-power modes - Essential for battery-operated IoT applications\n",
            "\n",
            "📝 Task 2.1: The Role of TensorFlow Lite (TFLite)\n",
            "TFLite is essential because:\n",
            "✓ Converts large Keras models to optimized .tflite format\n",
            "✓ Provides specialized runtime for resource-constrained devices\n",
            "✓ Reduces memory footprint and improves inference speed\n",
            "\n",
            "📝 Task 2.2: The Need for Quantization\n",
            "Quantization benefits:\n",
            "✓ Reduces model size by ~75% (float32 → int8)\n",
            "✓ Improves inference speed (integer operations are faster)\n",
            "✓ Reduces power consumption\n",
            "✓ Minimal accuracy loss for significant gains\n",
            "\n",
            "🚀 DEPLOYMENT FEASIBILITY ASSESSMENT:\n",
            "\n",
            "1. MEMORY CONSTRAINT ANALYSIS:\n",
            "   XIAO ESP32S3 SRAM: 512 KB\n",
            "   MLP TFLite Size: 242.7 KB → ✓ FITS\n",
            "   CNN TFLite Size: 62.4 KB → ✓ FITS\n",
            "\n",
            "2. PERFORMANCE ANALYSIS:\n",
            "   Processor: Dual-core 240 MHz LX7\n",
            "   Estimated MLP Inference Time: ~2.4 ms\n",
            "   Estimated CNN Inference Time: ~0.3 ms\n",
            "   Real-time requirement: < 100 ms → ✓ FEASIBLE\n",
            "\n",
            "3. ACCURACY ANALYSIS:\n",
            "   MLP Accuracy: Original=0.8794, TFLite=0.0927\n",
            "   CNN Accuracy: Original=0.8908, TFLite=0.2507\n",
            "   Accuracy loss: MLP=89.46%, CNN=71.86%\n",
            "\n",
            "🎯 FINAL DEPLOYMENT RECOMMENDATION:\n",
            "✓ BOTH models can be deployed on XIAO ESP32S3\n",
            "✓ Recommended model: CNN (better accuracy with smaller size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"# Task 5.1: Final Report and Conclusion\"\"\""
      ],
      "metadata": {
        "id": "nbJxlcprLpmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL COMPARISON REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create comprehensive comparison table\n",
        "comparison_data = [\n",
        "    [\"Model\", \"Test Accuracy\", \"TFLite Accuracy\", \"Trainable Parameters\", \"Keras Size (MB)\", \"TFLite Size (MB)\", \"TFLite Size (KB)\", \"Fits in SRAM?\"],\n",
        "    [\"MLP\", f\"{test_accuracy_mlp:.4f}\", f\"{mlp_tflite_accuracy:.4f}\", f\"{mlp_trainable:,}\", f\"{mlp_size:.2f}\", f\"{mlp_tflite_size:.2f}\", f\"{mlp_tflite_size_kb:.1f}\", f\"{'YES' if mlp_tflite_size_kb < xiao_sram_kb else 'NO'}\"],\n",
        "    [\"CNN\", f\"{test_accuracy_cnn:.4f}\", f\"{cnn_tflite_accuracy:.4f}\", f\"{cnn_trainable:,}\", f\"{cnn_size:.2f}\", f\"{cnn_tflite_size:.2f}\", f\"{cnn_tflite_size_kb:.1f}\", f\"{'YES' if cnn_tflite_size_kb < xiao_sram_kb else 'NO'}\"]\n",
        "]\n",
        "\n",
        "# Print formatted table\n",
        "print(f\"{'Model':<10} {'Test Acc':<12} {'TFLite Acc':<12} {'Params':<15} {'Keras MB':<10} {'TFLite MB':<10} {'TFLite KB':<12} {'Fits SRAM':<10}\")\n",
        "print(\"-\" * 90)\n",
        "for row in comparison_data[1:]:\n",
        "    print(f\"{row[0]:<10} {row[1]:<12} {row[2]:<12} {row[3]:<15} {row[4]:<10} {row[5]:<10} {row[6]:<12} {row[7]:<10}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANALYSIS AND CONCLUSIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Answer the questions\n",
        "print(\"\\n1. Which model achieved a higher accuracy?\")\n",
        "if test_accuracy_cnn > test_accuracy_mlp:\n",
        "    print(f\"   ✓ CNN model achieved higher accuracy ({test_accuracy_cnn:.4f} vs {test_accuracy_mlp:.4f})\")\n",
        "else:\n",
        "    print(f\"   ✓ MLP model achieved higher accuracy ({test_accuracy_mlp:.4f} vs {test_accuracy_cnn:.4f})\")\n",
        "\n",
        "print(\"\\n2. Which model had a smaller number of parameters (lower memory footprint)?\")\n",
        "if cnn_trainable < mlp_trainable:\n",
        "    print(f\"   ✓ CNN model has fewer parameters ({cnn_trainable:,} vs {mlp_trainable:,})\")\n",
        "else:\n",
        "    print(f\"   ✓ MLP model has fewer parameters ({mlp_trainable:,} vs {cnn_trainable:,})\")\n",
        "\n",
        "print(\"\\n3. TensorFlow Lite Conversion Results:\")\n",
        "print(f\"   ✓ MLP Size Reduction: {((mlp_size - mlp_tflite_size)/mlp_size)*100:.1f}%\")\n",
        "print(f\"   ✓ CNN Size Reduction: {((cnn_size - cnn_tflite_size)/cnn_size)*100:.1f}%\")\n",
        "print(f\"   ✓ Accuracy Preservation: MLP lost {((test_accuracy_mlp-mlp_tflite_accuracy)/test_accuracy_mlp*100):.2f}%, CNN lost {((test_accuracy_cnn-cnn_tflite_accuracy)/test_accuracy_cnn*100):.2f}%\")\n",
        "\n",
        "print(\"\\n4. XIAO ESP32S3 Deployment Feasibility:\")\n",
        "if mlp_tflite_size_kb < xiao_sram_kb and cnn_tflite_size_kb < xiao_sram_kb:\n",
        "    print(\"   ✓ BOTH models can be deployed on XIAO ESP32S3\")\n",
        "    print(\"   ✓ Recommended: CNN (better accuracy/efficiency trade-off)\")\n",
        "elif cnn_tflite_size_kb < xiao_sram_kb:\n",
        "    print(\"   ✓ CNN model can be deployed\")\n",
        "    print(\"   ✗ MLP model requires further optimization\")\n",
        "else:\n",
        "    print(\"   ✗ Both models require optimization for XIAO deployment\")\n",
        "\n",
        "print(\"\\n5. Why is CNN generally superior for image tasks on edge devices?\")\n",
        "print(\"   ✓ Better parameter efficiency (fewer parameters, similar accuracy)\")\n",
        "print(\"   ✓ Hierarchical feature learning preserves spatial relationships\")\n",
        "print(\"   ✓ Built-in translation invariance\")\n",
        "print(\"   ✓ Smaller memory footprint after quantization\")\n",
        "print(\"   ✓ Better suited for constrained environments like XIAO ESP32S3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LboQv0RELqXt",
        "outputId": "ac77c1da-59e2-4704-97dc-8aa537c7610c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL COMPARISON REPORT\n",
            "================================================================================\n",
            "Model      Test Acc     TFLite Acc   Params          Keras MB   TFLite MB  TFLite KB    Fits SRAM \n",
            "------------------------------------------------------------------------------------------\n",
            "MLP        0.8794       0.0927       235,146         2.72       0.24       242.7        YES       \n",
            "CNN        0.8908       0.2507       56,714          0.69       0.06       62.4         YES       \n",
            "\n",
            "================================================================================\n",
            "ANALYSIS AND CONCLUSIONS\n",
            "================================================================================\n",
            "\n",
            "1. Which model achieved a higher accuracy?\n",
            "   ✓ CNN model achieved higher accuracy (0.8908 vs 0.8794)\n",
            "\n",
            "2. Which model had a smaller number of parameters (lower memory footprint)?\n",
            "   ✓ CNN model has fewer parameters (56,714 vs 235,146)\n",
            "\n",
            "3. TensorFlow Lite Conversion Results:\n",
            "   ✓ MLP Size Reduction: 91.3%\n",
            "   ✓ CNN Size Reduction: 91.1%\n",
            "   ✓ Accuracy Preservation: MLP lost 89.46%, CNN lost 71.86%\n",
            "\n",
            "4. XIAO ESP32S3 Deployment Feasibility:\n",
            "   ✓ BOTH models can be deployed on XIAO ESP32S3\n",
            "   ✓ Recommended: CNN (better accuracy/efficiency trade-off)\n",
            "\n",
            "5. Why is CNN generally superior for image tasks on edge devices?\n",
            "   ✓ Better parameter efficiency (fewer parameters, similar accuracy)\n",
            "   ✓ Hierarchical feature learning preserves spatial relationships\n",
            "   ✓ Built-in translation invariance\n",
            "   ✓ Smaller memory footprint after quantization\n",
            "   ✓ Better suited for constrained environments like XIAO ESP32S3\n"
          ]
        }
      ]
    }
  ]
}